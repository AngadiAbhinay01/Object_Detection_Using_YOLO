import cv2
import numpy as np
import matplotlib.pyplot as plt

# Set the location and name of the cfg file
cfg_file = './yolov3.cfg'

# Set the location and name of the pre-trained weights file
weight_file = './yolov3.weights'

# Set the location and name of the COCO object classes file
namesfile = './coco.names'

# Load the COCO class names
with open(namesfile, 'r') as f:
    class_names = f.read().strip().split('\n')
print(class_names)

# Load the network architecture and pre-trained weights
net = cv2.dnn.readNetFromDarknet(cfg_file, weight_file)

layer_names = net.getLayerNames()

print("Layer names:")
for i, layer_name in enumerate(layer_names):
    print(f"Layer {i + 1}: {layer_name}")

# Load the image
img = cv2.imread('./images/food.jpg')
img.shape

# Get the width and height of the image
height, width = img.shape[:2]

# Create a blob from the image
blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)

# Set the input for the network
net.setInput(blob)

# Get the output layer names
ln = net.getLayerNames()
ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]
print(ln)

# Forward pass to get the output of the output layers
layer_outputs = net.forward(ln)
print(layer_outputs)

# Initialize lists to hold detection results
boxes = []
confidences = []
class_ids = []


# Loop over each of the layer outputs
for output in layer_outputs:
    
    for detection in output:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        
        if confidence > 0.5:
            box = detection[0:4] * np.array([width, height, width, height])
            print(box)
            (centerX, centerY, w, h) = box.astype('int')

            x = int(centerX - (w / 2))
            y = int(centerY - (h / 2))

            boxes.append([x, y, int(w), int(h)])
            confidences.append(float(confidence))
            class_ids.append(class_id)


# Apply non-maxima suppression to suppress weak and overlapping bounding boxes
indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)
print(indices)

# Draw the bounding boxes and class names on the image
if len(indices) > 0:
    for i in indices.flatten():
        box = boxes[i]
        (x, y, w, h) = box
        color = [int(c) for c in np.random.randint(0, 255, size=3)]
        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)
        text = f"{class_names[class_ids[i]]}: {confidences[i]:.2f}"
        cv2.putText(img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# Convert the image to RGB for plotting
rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Display the image with detections
plt.figure(figsize=(12, 8))
plt.imshow(rgb_image)
plt.title('Image with Object Detections')
plt.axis('off')
plt.show()



what is structured approach, you can clearly and comprehensively explain my object detection project to an interviewer.


1. Introduce the project
2. Describe the project modules
3. Detail the purpose and function of the project
4. Talk about the tools you used
5. Explain your contribution to the project
6. Mention challenges and how you overcame them
7. Highlight your teamwork skills
8. Note the duration of the project
9. Address the benefits and disadvantages of the project
